{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan age or birth age\n",
    "task = 'scan_age'\n",
    "\n",
    "model_name = 'MLP.pt'\n",
    "\n",
    "path = '/home/daniel/data/release/'\n",
    "\n",
    "# hyperparameters\n",
    "bs = 8\n",
    "lr = 0.001\n",
    "epochs = 500\n",
    "hidden = 64\n",
    "features = 'pos+norm+dha+x'\n",
    "\n",
    "in_channels = 0\n",
    "if 'pos' in features:\n",
    "    in_channels += 3\n",
    "if 'norm' in features:\n",
    "    in_channels += 3\n",
    "if 'dha' in features:\n",
    "    in_channels += 3\n",
    "if 'x' in features:\n",
    "    in_channels += 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from MLP import MLP, actor_MLP\n",
    "from GCN import GCN, actor_GCN\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00061XX04_ses-13300_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00084XX11_ses-31201_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00143AN12_ses-47501_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00170XX06_ses-56100_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00217XX11_ses-73700_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00221XX07_ses-75000_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00291XX12_ses-93100_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00307XX10_ses-98800_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00341XX12_ses-108000_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00319XX14_ses-117300_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/surfaces/sub-CC00439XX19_ses-132100_left.wm.surf.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00442XX14_ses-133300_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00371XX09_ses-134700_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00468XX15_ses-139100_left.shape.gii'\n",
      "No such file or no access: '/home/daniel/data/release/features/sub-CC00501XX06_ses-146500_left.shape.gii'\n"
     ]
    }
   ],
   "source": [
    "log_dir=f'runs/invase/{task}/{model_name}/features={features}/bs={bs}_lr={lr}_epoch={epochs}_hidden={hidden}'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_ids = pd.read_csv(task + '_train.txt', header=None)\n",
    "val_ids = pd.read_csv(task + '_val.txt', header=None)\n",
    "test_ids = pd.read_csv(task + '_test.txt', header=None)\n",
    "\n",
    "df = pd.read_csv(\"combined.tsv\", sep='\\t')\n",
    "\n",
    "df.insert(0, \"ID\", \"sub-\" + df[\"participant_id\"] + \"_\" + \"ses-\" + df[\"session_id\"].apply(str))\n",
    "df.drop(\"participant_id\", axis=1, inplace=True)\n",
    "df.drop(\"session_id\", axis=1, inplace=True)\n",
    "\n",
    "transform = T.Compose([T.NormalizeScale(), T.GenerateMeshNormals(), T.FaceToEdge()])\n",
    "\n",
    "def get_data(path, task, ids):\n",
    "    dataset = []\n",
    "    for _id in ids[0]:\n",
    "        try:\n",
    "            surface = nib.load(os.path.join(path, 'surfaces', _id + '_left.wm.surf.gii'))\n",
    "            pos, face = surface.agg_data()\n",
    "            feature = nib.load(os.path.join(path, 'features', _id + '_left.shape.gii'))\n",
    "            x = np.stack(feature.agg_data(), axis=1)\n",
    "            y = np.array([[df.loc[df['ID'] == _id, task].item()]])\n",
    "            data = Data()\n",
    "            data.id = _id\n",
    "            if 'x' in features:\n",
    "                data.x = torch.from_numpy(x).to(torch.float32)\n",
    "            data.pos = torch.from_numpy(pos).to(torch.float32)\n",
    "            data.face = torch.from_numpy(face.T).to(torch.long)\n",
    "            data.y = torch.from_numpy(y).to(torch.float32)\n",
    "            if task == 'birth_age':\n",
    "                confound = np.array([[df.loc[df['ID'] == _id, 'scan_age'].item()]])\n",
    "                data.confound = torch.from_numpy(confound).to(torch.float32)\n",
    "            data = transform(data)\n",
    "            if 'norm' not in features:\n",
    "                data.norm = None\n",
    "            if 'dha' in features:\n",
    "                data.dha = torch.from_numpy(np.load(os.path.join(path, 'preprocess/V_dihedral_angles', \\\n",
    "                                                                 _id + '_left.wm.surf_V_dihedralAngles.npy'))).to(torch.float32)\n",
    "            # data.eig = torch.from_numpy(np.load(os.path.join(path, 'preprocess/aligned_eigen_vectors',\n",
    "            #                                                     _id + '_left.wm.surf_eigen.npy'))).to(torch.float32)\n",
    "            # data.curv = torch.from_numpy(np.load(os.path.join(path, 'preprocess/gaussian_curvatures',\n",
    "            #                                                     _id + '_left.wm.surf_gaussian_curvature.npy'))).to(torch.float32).unsqueeze(1)\n",
    "            # data.curv = (data.curv - data.curv.min()) / (data.curv.max() - data.curv.min())\n",
    "            # data.hks = torch.from_numpy(np.load(os.path.join(path, 'preprocess/HKS',\n",
    "            #                                                 _id + '_left.wm.surf_hks.npy'))).to(torch.float32)\n",
    "            dataset.append(data)\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "    return dataset\n",
    "\n",
    "train_set = get_data(path, task, train_ids)\n",
    "val_set = get_data(path, task, val_ids)\n",
    "test_set = get_data(path, task, test_ids)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=bs)\n",
    "test_loader = DataLoader(test_set, batch_size=bs)\n",
    "\n",
    "class Invase():\n",
    "    def __init__(self):\n",
    "        if model_name == 'MLP.pt':\n",
    "            self.critic = MLP(in_channels=in_channels, hidden_channels=hidden, out_channels=1)\n",
    "            self.baseline = MLP(in_channels=in_channels, hidden_channels=hidden, out_channels=1)\n",
    "            self.actor = actor_MLP(in_channels=in_channels, hidden_channels=hidden, out_channels=in_channels)\n",
    "        elif model_name == 'GCN.pt':\n",
    "            self.critic = GCN(in_channels=in_channels, hidden_channels=hidden, out_channels=1)\n",
    "            self.baseline = GCN(in_channels=in_channels, hidden_channels=hidden, out_channels=1)\n",
    "            self.actor = actor_GCN(in_channels=in_channels, hidden_channels=hidden, out_channels=in_channels)\n",
    "        self.critic = self.critic.to(device)\n",
    "        self.critic.optimizer = torch.optim.AdamW(self.critic.parameters(), lr=lr)\n",
    "        self.critic.criterion = nn.MSELoss()\n",
    "        self.baseline = self.baseline.to(device)\n",
    "        self.baseline.optimizer = torch.optim.AdamW(self.baseline.parameters(), lr=lr)\n",
    "        self.baseline.criterion = nn.MSELoss()\n",
    "        self.actor = self.actor.to(device)\n",
    "        self.actor.optimizer = torch.optim.AdamW(self.actor.parameters(), lr=lr)\n",
    "        self.actor.criterion = self.actor_loss\n",
    "        self.lambda_ = 1.0\n",
    "\n",
    "    def actor_loss(self, actor_pred, actor_out, critic_out, baseline_out, y_true):\n",
    "        critic_loss = F.mse_loss(critic_out, y_true)\n",
    "        baseline_loss = F.mse_loss(baseline_out, y_true)\n",
    "        reward = -(critic_loss - baseline_loss)\n",
    "        # reward * BCE(actor_pred, actor_out) - lambda * ||actor_pred||\n",
    "        custom_actor_loss = reward * torch.sum(actor_out * torch.log(actor_pred + 1e-8) + \\\n",
    "                                               (1.0 - actor_out)* torch.log(1.0 - actor_pred + 1e-8), dim=1) - \\\n",
    "                                                self.lambda_ * torch.mean(actor_pred, dim=1)\n",
    "        custom_actor_loss = torch.mean(-custom_actor_loss)\n",
    "        return custom_actor_loss\n",
    "\n",
    "invase = Invase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader, invase):\n",
    "    actor_losses = []\n",
    "    critic_losses = []\n",
    "    critic_accs = []\n",
    "    baseline_losses = []\n",
    "    baseline_accs = []\n",
    "    invase.baseline.eval()\n",
    "    invase.critic.eval()\n",
    "    invase.actor.eval()\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        # baseline testing\n",
    "        baseline_out = invase.baseline(data)\n",
    "        baseline_loss = invase.baseline.criterion(baseline_out, data.y)\n",
    "        baseline_losses.append(baseline_loss.item())\n",
    "        baseline_acc = F.l1_loss(baseline_out, data.y)\n",
    "        baseline_accs.append(baseline_acc.item())\n",
    "        # critic testing\n",
    "        selection_probability = invase.actor(data)\n",
    "        selection = torch.bernoulli(selection_probability)\n",
    "        critic_out = invase.critic(data, selection)\n",
    "        critic_loss = invase.critic.criterion(critic_out, data.y)\n",
    "        critic_losses.append(critic_loss.item())\n",
    "        critic_acc = F.l1_loss(critic_out, data.y)\n",
    "        critic_accs.append(critic_acc.item())\n",
    "        # actor testing\n",
    "        actor_loss = invase.actor.criterion(selection_probability, selection, critic_out, baseline_out, data.y)\n",
    "        actor_losses.append(actor_loss.item())\n",
    "        return sum(actor_losses) / len(actor_losses), \\\n",
    "               sum(critic_losses) / len(critic_losses), sum(critic_accs) / len(critic_accs), \\\n",
    "               sum(baseline_losses) / len(baseline_losses), sum(baseline_accs) / len(baseline_accs)\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_reg(loader, invase):\n",
    "    invase.baseline.eval()\n",
    "    invase.critic.eval()\n",
    "    invase.actor.eval()\n",
    "    baseline_outs = []\n",
    "    critic_outs = []\n",
    "    ys = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        baseline_out = invase.baseline(data)\n",
    "        baseline_outs.append(baseline_out.cpu().numpy())\n",
    "        selection_probability = invase.actor(data)\n",
    "        selection = torch.bernoulli(selection_probability)\n",
    "        critic_out = invase.critic(data, selection)\n",
    "        critic_outs.append(critic_out.cpu().numpy())\n",
    "        ys.append(data.y.cpu().numpy())\n",
    "    plt.scatter(np.concatenate(ys), np.concatenate(baseline_outs))\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('baseline_out')\n",
    "    plt.savefig(os.path.join(log_dir, 'baseline_regression.png'))\n",
    "    plt.close()\n",
    "    plt.scatter(np.concatenate(ys), np.concatenate(critic_outs))\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('critic_out')\n",
    "    plt.savefig(os.path.join(log_dir, 'critic_regression.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invase.baseline.load_state_dict(torch.load(os.path.join(log_dir, model_name + '_baseline')))\n",
    "invase.critic.load_state_dict(torch.load(os.path.join(log_dir, model_name + '_critic')))\n",
    "invase.actor.load_state_dict(torch.load(os.path.join(log_dir, model_name + '_actor')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(test_loader, invase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5484633445739746,\n",
       " 0.309556782245636,\n",
       " 0.47713756561279297,\n",
       " 0.3347516655921936,\n",
       " 0.4844222068786621)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader, invase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in test_set:\n",
    "        invase.baseline.eval()\n",
    "        invase.critic.eval()\n",
    "        invase.actor.eval()\n",
    "        data = data.to(device)\n",
    "        baseline_out = invase.baseline(data)\n",
    "        selection_probability = invase.actor(data)\n",
    "        selection = torch.bernoulli(selection_probability)\n",
    "        np.save('selection/' + data.id, selection.cpu().numpy())\n",
    "        critic_out = invase.critic(data, selection)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
